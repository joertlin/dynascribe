{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "423b9957-5718-49da-8e8b-86e9222ae834",
   "metadata": {},
   "source": [
    "# Import the required modules:\n",
    "[Nvidia - NeMo docs](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/starthere/intro.html)  \n",
    "https://github.com/NVIDIA/NeMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f6811b7-202b-464b-8601-96ca31b3505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import nemo.collections.asr as nemo_asr\n",
    "\n",
    "from nemo.collections.asr.metrics.wer import WER\n",
    "from nemo.collections.asr.modules.audio_preprocessing import AudioToMelSpectrogramPreprocessor\n",
    "from nemo.collections.asr.parts.features import WaveformFeaturizer\n",
    "#from nemo.collections.asr.modules import CTCDecoder\n",
    "\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ddfd201-e9dc-4659-a8f1-f03e893fa306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2c8fcbb-136e-4752-9f99-4a059c736b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-05-09 17:55:05 cloud:58] Found existing object C:\\Users\\blaze\\.cache\\torch\\NeMo\\NeMo_1.17.0\\QuartzNet15x5Base-En\\2b066be39e9294d7100fb176ec817722\\QuartzNet15x5Base-En.nemo.\n",
      "[NeMo I 2023-05-09 17:55:05 cloud:64] Re-using file from: C:\\Users\\blaze\\.cache\\torch\\NeMo\\NeMo_1.17.0\\QuartzNet15x5Base-En\\2b066be39e9294d7100fb176ec817722\\QuartzNet15x5Base-En.nemo\n",
      "[NeMo I 2023-05-09 17:55:05 common:913] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2023-05-09 17:55:06 features:287] PADDING: 16\n",
      "[NeMo I 2023-05-09 17:55:07 save_restore_connector:247] Model EncDecCTCModel was successfully restored from C:\\Users\\blaze\\.cache\\torch\\NeMo\\NeMo_1.17.0\\QuartzNet15x5Base-En\\2b066be39e9294d7100fb176ec817722\\QuartzNet15x5Base-En.nemo.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained model\n",
    "model = nemo_asr.models.EncDecCTCModel.from_pretrained(model_name=\"QuartzNet15x5Base-En\")\n",
    "\n",
    "# Load the audio file\n",
    "#file_path = \"path/to/your/audio.wav\"\n",
    "file_path = r\"C:\\scratch\\nemotest\\hello_world.wav\"\n",
    "\n",
    "#Read the audio file\n",
    "samples, sample_rate = sf.read(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcc6be98-f956-4343-b42a-6f6229861d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188075"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7a44386-a9ea-4919-aef9-c95fe3d790bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e652a9dc-76bf-49ae-b100-379d18104c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([188075])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_length = torch.tensor(samples.shape[0]).unsqueeze(0)\n",
    "samples_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "560c48a0-6658-445d-a559-920cdc2c67b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000e+00, -3.0518e-05, -3.0518e-05,  ...,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00], dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_tensor = torch.from_numpy(samples)\n",
    "samples_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30922c76-8708-4980-a29d-251fe078418e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00, -3.0518e-05, -3.0518e-05,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00]], dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_2d = samples_tensor.unsqueeze(0)\n",
    "samples_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba299181-b878-469f-a602-ac44b711f87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.size>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_2d.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1564a163-aad0-4b99-bada-6e164a612c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-05-09 17:55:14 features:287] PADDING: 16\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the preprocessor\n",
    "preprocessor = AudioToMelSpectrogramPreprocessor(\n",
    "    sample_rate=sample_rate,\n",
    "    window_size=0.02,\n",
    "    window_stride=0.01,\n",
    "    n_fft=512,\n",
    "    #num_mels=64,\n",
    "    preemph=0.97,\n",
    "    dither=1e-5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03647b85-e22e-4c5e-b54e-d2aae55c65ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AudioToMelSpectrogramPreprocessor(\n",
       "  (featurizer): FilterbankFeatures()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07c7e8eb-c13a-42dd-8b18-a7012b24cf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the waveform to log-mel spectrograms\n",
    "mel_spectrogram = preprocessor(input_signal=samples_2d, length=samples_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "960541bb-1e1c-4323-a84c-60492cb8a5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-2.4551, -2.4571, -0.2572,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [-2.0071, -2.0077, -0.8349,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [-1.8188, -1.8189, -1.2041,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [-2.1905, -2.3248,  0.9957,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [-1.8807, -2.0942,  0.7208,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [-1.5767, -1.6665,  0.0897,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "        dtype=torch.float64),\n",
       " tensor([1176]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96d525d7-1588-4412-95d5-e067f3cdee19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.4551, -2.4571, -0.2572,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-2.0071, -2.0077, -0.8349,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-1.8188, -1.8189, -1.2041,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [-2.1905, -2.3248,  0.9957,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-1.8807, -2.0942,  0.7208,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-1.5767, -1.6665,  0.0897,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the input tensor\n",
    "#input_tensor = mel_spectrogram[0]squeeze(0).unsqueeze(0).to(device)\n",
    "input_tensor = mel_spectrogram[0].to(torch.float32).to(device)\n",
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5438ece-fcbc-4305-bd43-3e598d013daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1176])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_spectrogram[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3f62b99-dfdd-4ea4-bb80-72061db5c447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1176"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(mel_spectrogram[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fde37dc8-86b5-4439-b818-667ecce1dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform ASR\n",
    "log_probs, sequence_length, greedy_token_predictions = model.forward(\n",
    "    processed_signal=input_tensor, \n",
    "    processed_signal_length=mel_spectrogram[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd1e5604-d124-458f-bee5-870a673c6f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-5.9711e+00, -7.9439e+00, -7.7328e+00,  ..., -9.4916e+00,\n",
       "          -8.6795e+00, -1.0398e-02],\n",
       "         [-6.3059e+00, -8.7399e+00, -8.3855e+00,  ..., -1.0523e+01,\n",
       "          -8.5935e+00, -5.4330e-03],\n",
       "         [-7.0969e+00, -9.0191e+00, -8.6317e+00,  ..., -1.0379e+01,\n",
       "          -9.6912e+00, -3.8902e-03],\n",
       "         ...,\n",
       "         [-2.3329e+00, -3.2861e+00, -3.4251e+00,  ..., -4.2241e+00,\n",
       "          -3.4887e+00, -2.7281e+00],\n",
       "         [-2.3329e+00, -3.2861e+00, -3.4251e+00,  ..., -4.2241e+00,\n",
       "          -3.4887e+00, -2.7281e+00],\n",
       "         [-2.3329e+00, -3.2861e+00, -3.4251e+00,  ..., -4.2241e+00,\n",
       "          -3.4887e+00, -2.7281e+00]]], device='cuda:0',\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a49c2550-3ece-4746-a09c-01344df25d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([588])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9b5334a-ffca-4827-bb8e-1b0432b67d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
       "         28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
       "         28, 28, 28, 28, 28, 28, 28, 28, 28,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0, 28,  0, 28,  0, 28,  0, 28,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,  5,\n",
       "         18,  5,  5,  5, 28, 28, 18, 28, 28, 28,  0, 28, 28, 28, 28, 28, 28, 28,\n",
       "          0, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
       "         28, 28, 28,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 28,  0, 28, 28,\n",
       "         28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,  0, 28,  0, 28,\n",
       "          0, 28,  0,  0,  0, 28, 28, 28,  0,  0,  0, 28, 28, 28, 28, 28, 28, 28,\n",
       "          0, 28, 28, 28, 28, 28, 28, 28,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0, 28, 28, 28, 28,  5,  5,  5,  5,  5,  5,\n",
       "          5,  5, 28, 28, 28, 28, 28, 28,  0, 20, 20, 20, 20, 20, 20, 28, 28, 28,\n",
       "         28,  0, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
       "         28, 28, 28, 28, 28,  0,  0,  0,  0,  0,  0,  0,  0, 28, 28, 28, 28, 28,\n",
       "         28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
       "         28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
       "         28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,  0,  0,  0,  0,  0, 28, 28,\n",
       "         28, 28, 28, 28, 28, 28, 28, 28,  0,  0, 28, 28, 28, 28, 28, 28, 28, 28,\n",
       "         28, 28, 28,  0,  0,  0, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
       "         28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,  0, 28,  0, 28, 28, 28,\n",
       "         28, 28, 28, 28, 28, 28, 28, 28,  0,  0,  0, 28, 28, 28, 28, 28, 28, 28,\n",
       "         28, 28, 28,  0,  0,  0,  0,  0, 28, 28, 28,  5, 28, 28, 28,  0,  0, 28,\n",
       "         28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
       "         28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
       "         28, 28, 28,  0, 28,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,  0,  0,  0, 28,\n",
       "         28, 28, 28, 12, 12, 12, 12, 28, 28, 28, 28, 28, 28, 28, 28, 28,  0, 28,\n",
       "         28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
       "         28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
       "         28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,  0,  0,  0,  0]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greedy_token_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67a17445-e14b-48b7-96fe-9beba6b373f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.5514e-03, 3.5483e-04, 4.3821e-04,  ..., 7.5487e-05,\n",
       "          1.7004e-04, 9.8966e-01],\n",
       "         [1.8256e-03, 1.6006e-04, 2.2814e-04,  ..., 2.6899e-05,\n",
       "          1.8531e-04, 9.9458e-01],\n",
       "         [8.2764e-04, 1.2108e-04, 1.7836e-04,  ..., 3.1081e-05,\n",
       "          6.1823e-05, 9.9612e-01],\n",
       "         ...,\n",
       "         [9.7019e-02, 3.7400e-02, 3.2545e-02,  ..., 1.4639e-02,\n",
       "          3.0540e-02, 6.5344e-02],\n",
       "         [9.7019e-02, 3.7400e-02, 3.2545e-02,  ..., 1.4639e-02,\n",
       "          3.0540e-02, 6.5344e-02],\n",
       "         [9.7019e-02, 3.7400e-02, 3.2545e-02,  ..., 1.4639e-02,\n",
       "          3.0540e-02, 6.5344e-02]]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs_soft_max = torch.nn.functional.softmax(log_probs, dim=-1)\n",
    "log_probs_soft_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66560ed5-eac4-47eb-ad1a-76d122b37da3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CTCDecoding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Define the CTC decoding object\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m decoder \u001b[38;5;241m=\u001b[39m \u001b[43mCTCDecoding\u001b[49m(blank_index\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mblank_index)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CTCDecoding' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the CTC decoding object\n",
    "decoder = CTCDecoding(blank_index=model.decoder.blank_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3e5a9b-4bd1-4c20-8585-15a9171dd724",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.decoder(log_probs=log_probs_soft_max).argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f647fc94-463c-4fea-99b3-2b95651db1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model._wer.ctc_decoder_predictions_tensor(log_probs_soft_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a195d7-ad3b-4c7b-a0f1-2fc2c5bc07e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = ''.join(model._wer.get_tokenizer().ids_to_text(output[0].cpu().detach().numpy().tolist()))\n",
    "print(\"Transcription:\", transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2473d2c-702c-419d-81be-a62b9924dc90",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Example from nvidia library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5b25fa7-7cae-4c04-98b3-33270b70dbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is an example of all CTC-based models:\n",
    "#nemo_asr.models.EncDecCTCModel.list_available_models()\n",
    "# More ASR Models are available - see: nemo_asr.models.ASRModel.list_available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b75be22-3152-437d-8810-49c1b9fb7d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-05-09 17:56:05 cloud:58] Found existing object C:\\Users\\blaze\\.cache\\torch\\NeMo\\NeMo_1.17.0\\QuartzNet15x5Base-En\\2b066be39e9294d7100fb176ec817722\\QuartzNet15x5Base-En.nemo.\n",
      "[NeMo I 2023-05-09 17:56:05 cloud:64] Re-using file from: C:\\Users\\blaze\\.cache\\torch\\NeMo\\NeMo_1.17.0\\QuartzNet15x5Base-En\\2b066be39e9294d7100fb176ec817722\\QuartzNet15x5Base-En.nemo\n",
      "[NeMo I 2023-05-09 17:56:05 common:913] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2023-05-09 17:56:05 features:287] PADDING: 16\n",
      "[NeMo I 2023-05-09 17:56:06 save_restore_connector:247] Model EncDecCTCModel was successfully restored from C:\\Users\\blaze\\.cache\\torch\\NeMo\\NeMo_1.17.0\\QuartzNet15x5Base-En\\2b066be39e9294d7100fb176ec817722\\QuartzNet15x5Base-En.nemo.\n"
     ]
    }
   ],
   "source": [
    "# Speech Recognition model - Citrinet initially trained on Multilingual LibriSpeech English corpus, and fine-tuned on the open source Aishell-2\n",
    "asr_model = nemo_asr.models.EncDecCTCModel.from_pretrained(model_name=\"QuartzNet15x5Base-En\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fa34b6d-73fd-4334-8c21-c0402886b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: The audio must be mono with 16Khz sampling rate\n",
    "audio_sample = r'C:\\scratch\\nemotest\\hello_world.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0120c7ed-8f5d-42a3-928c-882068d0974f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "657c6da647cd478294c512a8e7a731d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transcribed_text = asr_model.transcribe([audio_sample])\n",
    "#print(transcribed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f9d0a8d-aaa6-44db-a8ad-5641a813918d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this is a recording we are testing a python library called nemo hello world']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribed_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
